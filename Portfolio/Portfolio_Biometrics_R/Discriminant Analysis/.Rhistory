for (i in 1:4) preds_test[, i] <- predict(mod_pls, ncomp = i,data=Iris_test)
preds_test[preds_test<0] <- -1
preds_test[preds_test>0] <- 1
# Look at the results from each of the components:
for (i in 1:4) {
ct <- table(Iris_train$Y, preds_test[,i])
CV_error <- 1-sum(diag(prop.table(ct)))
print(CV_error)
}
mod_pls <- plsr(Y ~ X, ncomp = 4, data = Iris_train,
validation="LOO", scale = TRUE, jackknife = TRUE)
preds <- array(dim = c(length(Iris_train[, 1]), 4))
for (i in 1:4) preds[,i]<- apply(predict(mod_pls, ncomp = i), 1, which.max)
preds2 <- array(dim = c(length(Iris_train[, 1]), 4))
preds2[preds==1] <- "c"
preds2[preds==2] <- "s"
preds2[preds==3] <- "v"
# Look at the results from each of the components:
for (i in 1:4) {
ct <- table(Iris_train$Sp, preds2[, i])
CV_error <- 1 - sum(diag(prop.table(ct)))
print(CV_error)
}
##Random forests####
?apply
x <- cbind(x1 = 3, x2 = c(4:1, 2:5))
x
apply(x[,2], 1,which.max )
x[,2]
apply(x[,2], 2,which.max)
apply(x, 1,which.max )
apply(x, 1,sum )
x2
x[2]
x[,2]
apply(x[,2], 1,which.sum )
apply(x[,2], 1,which.max)
apply(x, 1,which.max )
for (i in 1:4) preds[,i]<- apply(predict(mod_pls, ncomp = i), 1, which.max)
preds
x<-predict(mod_pls, ncomp = i)
x
predict(mod_pls, ncomp = 4)
Iris_train$Y
preds2 <- array(dim = c(length(Iris_train[, 1]), 4))
preds2[preds==1] <- "c"
preds2[preds==2] <- "s"
preds2[preds==3] <- "v"
# Look at the results from each of the components:
for (i in 1:4) {
ct <- table(Iris_train$Sp, preds2[, i])
CV_error <- 1 - sum(diag(prop.table(ct)))
print(CV_error)
}
JCFWine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/Discriminant Analysis")
JCFWine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
View(JCFWine)
par(mar=c(4,2,3,2),mfrow=c(3,4))
for (i in 3:15) boxplot(JCFWine[,i] ~ JCFWine[,2],
JCFWine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
par(mar=c(4,2,3,2),mfrow=c(3,4))
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/Discriminant Analysis")
JCFWine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
par(mar=c(4,2,3,2),mfrow=c(3,4))
for (i in 3:15) boxplot(JCFWine[,i] ~ JCFWine[,2],
col = 1:3, main = names(JCFWine)[i])
outlier<-JCFWine[JCFWine[,15]>1800,]
winepc_without=PCA(scale(JCFWine[,3:15], scale = FALSE))
library(ChemometricsWithRData)
library(ChemometricsWithR)
par(mar=c(4,2,3,2),mfrow=c(3,4))
for (i in 3:15) boxplot(JCFWine[,i] ~ JCFWine[,2],
col = 1:3, main = names(JCFWine)[i])
outlier<-JCFWine[JCFWine[,15]>1800,]
##WITHOUT Standardization - ONLY with centering####
winepc_without=PCA(scale(JCFWine[,3:15], scale = FALSE))
par(mar=c(4,2,3,2),mfrow=c(2,2))
scoreplot(winepc_without, col = JCFWine$Wine, main = "Scores")
loadingplot(winepc_without, show.names = TRUE, main = "Loadings")
biplot(winepc_without, score.col = JCFWine$Wine, main = "biplot")
screeplot(winepc_without, type = "percentage", main = "Explained variance")
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/PCA")
JCFWine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
View(JCFWine)
data(wines, package = "ChemometricsWithRData")
View(wines)
par(mar=c(4,2,3,2),mfrow=c(3,4))
for (i in 3:15) boxplot(JCFWine[,i] ~ JCFWine[,2],
col = 1:3, main = names(JCFWine)[i])
outlier<-JCFWine[JCFWine[,15]>1800,]
##WITHOUT Standardization - ONLY with centering####
winepc_without=PCA(scale(JCFWine[,3:15], scale = FALSE))
par(mar=c(4,2,3,2),mfrow=c(2,2))
scoreplot(winepc_without, col = JCFWine$Wine, main = "Scores")
loadingplot(winepc_without, show.names = TRUE, main = "Loadings")
biplot(winepc_without, score.col = JCFWine$Wine, main = "biplot")
screeplot(winepc_without, type = "percentage", main = "Explained variance")
#with both
winepc=PCA(scale(JCFWine[,3:15]))
par(mar=c(4,2,3,2),mfrow=c(2,2))
scoreplot(winepc, col = JCFWine$Wine, main = "Scores")
loadingplot(winepc, show.names = TRUE, main = "Loadings")
biplot(winepc, score.col = JCFWine$Wine, main = "biplot")
screeplot(winepc, type = "percentage", main = "Explained variance")
cor(JCFWine[3:15])
wine<-read.csv("VIN2.csv",head=T,sep=";",dec=",")
View(wine)
library(ChemometricsWithRData)
library(ChemometricsWithR)
par(mar=c(4,2,3,2),mfrow=c(3,4))
for (i in 3:15) boxplot(wine[,i] ~ wine[,2],
col = 1:3, main = names(wine)[i])
outlier<-wine[wine[,15]>1800,]
##WITHOUT Standardization - ONLY with centering####
winepc_without=PCA(scale(wine[,3:15], scale = FALSE))
par(mar=c(4,2,3,2),mfrow=c(2,2))
scoreplot(winepc_without, col = wine$Wine, main = "Scores")
loadingplot(winepc_without, show.names = TRUE, main = "Loadings")
biplot(winepc_without, score.col = wine$Wine, main = "biplot")
screeplot(winepc_without, type = "percentage", main = "Explained variance")
#with both
winepc=PCA(scale(wine[,3:15]))
par(mar=c(4,2,3,2),mfrow=c(2,2))
scoreplot(winepc, col = wine$Wine, main = "Scores")
loadingplot(winepc, show.names = TRUE, main = "Loadings")
biplot(winepc, score.col = wine$Wine, main = "biplot")
screeplot(winepc, type = "percentage", main = "Explained variance")
cor(wine[3:15])
View(wine)
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/Discriminant Analysis")
data(iris3)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
Iris
Iris
set.seed(4897)
train <- sample(1:178, 178/2)
test <- (1:178)[-train]
wine_train <- wine[train,]
wine_test <- wine[test,]
table(wine_train$Sp)
table(wine_test$Sp)
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/Discriminant Analysis")
data(iris3)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
# We make a test and training data:
set.seed(4897)
train <- sample(1:150, 75)
test <- (1:150)[-train]
Iris_train <- Iris[train,]
Iris_test <- Iris[test,]
# Distribution in three classes in training data:
table(Iris_train$Sp)
table(Iris_test$Sp)
table(wine_train$Wine)
table(wine_test$Wine)
View(wine_train)
View(wine_train)
View(wine_train)
wine_train[,1]
library(MASS)
lda_train_LOO <- lda(Wine ~ F1+F2+F3+F4+F5+F6+F7+F8+F9+F10+F11+F12+F13,wine_train, prior = c(1, 1, 1)/3, CV = TRUE)
ct <- table(wine_train$Sp, lda_train_LOO$class)
ct <- table(wine_train$Wine, lda_train_LOO$class)
diag(prop.table(ct, 1))
sum(diag(prop.table(ct)))
library(MASS)
lda_train_LOO <- lda(Wine ~. -row.names - X-Wine,wine_train, prior = c(1, 1, 1)/3, CV = TRUE)
lda_train_LOO <- lda(Wine ~.  - X-Wine,wine_train, prior = c(1, 1, 1)/3, CV = TRUE)
ct <- table(wine_train$Wine, lda_train_LOO$class)
diag(prop.table(ct, 1))
sum(diag(prop.table(ct)))
library(klaR) #only works without the CV
library(klaR) #only works without the CV
partimat(Wine ~.- X-Wine,data = wine_train, method = "lda", prior=c(1, 1, 1)/3)
library(klaR) #only works without the CV
partimat(Wine ~.- X- Wine,data = wine_train, method = "lda", prior=c(1, 1, 1)/3)
library(klaR) #only works without the CV
partimat(Wine ~. -X- Wine,wine_train, method = "lda", prior=c(1, 1, 1)/3)
? partimat
? partimat
library(klaR) #only works without the CV
partimat(Wine ~. -X- Wine,data=wine_train, method = "lda",  plot.matrix = TRUE, imageplot = FALSE,prior=c(1, 1, 1)/3)
setwd("C:/Users/RAN/OneDrive/Documents/BioDataAnalysis/Data/Discriminant Analysis")
ata(iris3)
Iris <- data.frame(rbind(iris3[,,1], iris3[,,2], iris3[,,3]),
Sp = rep(c("s","c","v"), rep(50,3)))
# We make a test and training data:
set.seed(4897)
train <- sample(1:150, 75)
test <- (1:150)[-train]
Iris_train <- Iris[train,]
Iris_test <- Iris[test,]
# Distribution in three classes in training data:
table(Iris_train$Sp)
table(Iris_test$Sp)
## PART 1: LDA####
library(MASS)
lda_train_LOO <- lda(Sp ~ Sepal.L. + Sepal.W. + Petal.L. + Petal.W.,Iris_train, prior = c(1, 1, 1)/3, CV = TRUE)
# Assess the accuracy of the prediction
# percent correct for each category:
ct <- table(Iris_train$Sp, lda_train_LOO$class)
diag(prop.table(ct, 1))
# total percent correct
sum(diag(prop.table(ct)))
library(klaR) #only works without the CV
partimat(Sp ~ Sepal.L. + Sepal.W. + Petal.L. + Petal.W.,
data = Iris_train, method = "lda", prior=c(1, 1, 1)/3)
qda_train_LOO <- qda(Wine ~.- X-Wine,wine_train, prior = c(1, 1, 1)/3, CV = TRUE)
qda_train <- qda(Wine ~.- X-Wine,wine_train, prior = c(1, 1, 1)/3, CV = F)
# Assess the accuracy of the prediction
# percent correct for each category:
ct <- table(wine_train$Wine, qda_train_LOO$class)
ct
diag(prop.table(ct, 1))
sum(diag(prop.table(ct)))
#[1] 0.96 For this example the QDA performs slightly worse than the LDA.
partimat(Wine ~.- X-Wine,data = wine_train, method = "qda", prior = c(1, 1, 1)/3)
partimat(Wine ~.- X-Wine,data = wine_train, method = "qda", prior = c(1, 1, 1)/3,plot.matrix = F, imageplot = FALSE,)
partimat(Wine ~.- X-Wine,data = wine_train, method = "qda", prior = c(1, 1, 1)/3,plot.matrix = TRUE, imageplot = FALSE,)
partimat(Wine ~.- X-Wine,data = wine_train, method = "qda", prior = c(1, 1, 1)/3,plot.matrix = F, imageplot = FALSE)
TRUE
partimat(Wine ~.- X-Wine,data = wine_train, method = "qda", prior = c(1, 1, 1)/3,plot.matrix = TRUE, imageplot = FALSE)
predict(qda_train, Iris_test)$class
predict(qda_train, wine_test)$class
ct <- table(Iris_test$Sp, predict(qda_train, Iris_test)$class)
ct
diag(prop.table(ct, 1))
sum(diag(prop.table(ct)))
partimat(Wine ~.- X-Wine,data = wine_train, method = "naiveBayes",
prior=c(1, 1, 1)/3, usekernel = TRUE)
partimat(Wine ~.- X-Wine,data = wine_train, method = "naiveBayes",
prior=c(1, 1, 1)/3, plot.matrix = TRUE, imageplot = FALSE, usekernel = TRUE)
bayes_fit <- suppressWarnings(NaiveBayes(Wine ~.- X-Wine,data = wine_train, method = "naiveBayes",prior = c(1, 1, 1)/3, usekernel = TRUE))
par(mfrow = c(2, 2))
plot(bayes_fit)
bayes_fit <- suppressWarnings(NaiveBayes(Wine ~.- X-Wine,data = wine_train, method = "naiveBayes",prior = c(1, 1, 1)/3, usekernel = TRUE))
par(mfrow = c(2, 2))
plot(bayes_fit)
partimat(Wine ~.- X-Wine,data = wine[train,], method = "sknn", kn = 3)
bayes_fit <- suppressWarnings(NaiveBayes(Wine ~.- X-Wine,data = wine_train, method = "naiveBayes",prior = c(1, 1, 1)/3, usekernel = TRUE,plot.matrix = TRUE, imageplot = FALSE,))
partimat(Wine ~.- X-Wine,data = wine[train,],plot.matrix = TRUE, imageplot = FALSE, method = "sknn", kn = 3)
knn_5_preds <- predict(knn_fit_5, wine_test)$class
wine_train$Y <- -1
wine_train$Y[wine_train$Wine == "Barbera"] <- 1
wine_train$Y
table(wine_train$Y)
wine_train$X <- as.matrix(wine_train[, 1:4])
wine_train[1]
wine_train[,1]
wine_train$X <- as.matrix(wine_train[, 3:15])
# From here use standard PLS1 predictions, e.g.:
wine_train$X
table(wine_train$Y)
wine_train$X <- as.matrix(wine_train[, 3:15])
library(pls)
mod_pls <- plsr(Y ~X , ncomp = 4, data =wine_train,
validation = "LOO", scale = TRUE, jackknife = TRUE)
par(mfrow = c(2, 2))
plot(mod_pls, labels = rownames(wine_train), which = "validation")
plot(mod_pls, "validation", estimate = c("train", "CV"),legendpos = "topright")
plot(mod_pls, "validation", estimate = c("train", "CV"),
val.type = "R2", legendpos = "bottomright")
pls::scoreplot(mod_pls, labels = wine_train$Wine,pch=19, col=as.numeric(wine_train$Wine))
preds <- array(dim = c(length(wine_train[, 1]), 4)) #75 by 4 array
for (i in 1:4) preds[, i] <- predict(mod_pls, ncomp = i)
preds[preds<0] <- -1
preds[preds>0] <- 1
for (i in 1:4) {
ct <- table(wine_train$Y, preds[,i])
CV_error <- 1-sum(diag(prop.table(ct)))
print(CV_error)
}
preds <- array(dim = c(length(wine_train[, 1]), 13)) #75 by 13 array
for (i in 1:13) preds[, i] <- predict(mod_pls, ncomp = i)
length(wine_train[, 1])
wine_train
(wine_train[, 1]
wine_train[, 1]
wine_train[, 1]
preds <- array(dim = c(length(wine_train[, 1]), 4)) #75 by 4 array
preds
preds <- array(dim = c(length(wine_train[, 1]), 4)) #75 by 4 array
preds
set.seed(4897)
train <- sample(1:178, 178/2)
test <- (1:178)[-train]
wine_train <- wine[train,]
wine_test <- wine[test,]
# Distribution in three classes in training data:
table(wine_train$Wine)
table(wine_test$Wine)
preds <- array(dim = c(length(wine_train[, 1]), 4)) #75 by 4 array
preds
for (i in 1:4) preds[, i] <- predict(mod_pls, ncomp = i)
preds
preds[preds<0] <- -1
preds[preds>0] <- 1
preds
for (i in 1:4) {
ct <- table(wine_train$Y, preds[,i])
CV_error <- 1-sum(diag(prop.table(ct)))
print(CV_error)
}
wine_train$Y
wine_train$Y <- -1
wine_train$Y[wine_train$Wine == "Barbera"] <- 1
table(wine_train$Y)
wine_train$Y
wine_train[, 3:15]
wine_train$X <- as.matrix(wine_train[, 3:15])
library(pls)
mod_pls <- plsr(Y ~X , ncomp = 4, data =wine_train,
validation = "LOO", scale = TRUE, jackknife = TRUE)
par(mfrow = c(2, 2))
plot(mod_pls, labels = rownames(wine_train), which = "validation")
plot(mod_pls, "validation", estimate = c("train", "CV"),legendpos = "topright")
plot(mod_pls, "validation", estimate = c("train", "CV"),
val.type = "R2", legendpos = "bottomright")
pls::scoreplot(mod_pls, labels = wine_train$Wine,pch=19, col=as.numeric(wine_train$Wine))
length(wine_train[, 1])
wine_train
wine_train$Y
wine_train$Y[, 1]
wine_train$Y[, 1]
length(wine_train$Y[, 1])
wine_train$Y
length(wine_train$Y[1])
length(wine_train[,1])
wine_train$Y
length(wine_train[1,])
length(wine_train[,1])
length(wine_test[,1])
preds <- array(dim = c(length(wine_test[,1]), 4)) #75 by 4 array
for (i in 1:4) preds[, i] <- predict(mod_pls, ncomp = i)
preds[preds<0] <- -1
preds[preds>0] <- 1
for (i in 1:4) {
ct <- table(wine_train$Y, preds[,i])
CV_error <- 1-sum(diag(prop.table(ct)))
print(CV_error)
}
length(wine_train[, 1])
preds_test <- array(dim = c(length(wine_test[, 1]), 4))
for (i in 1:4) preds_test[, i] <- predict(mod_pls, ncomp = i,data=wine_test)
preds_test[preds_test<0] <- -1
preds_test[preds_test>0] <- 1
# Look at the results from each of the components:
for (i in 1:4) {
ct <- table(wine_train$Y, preds_test[,i])
CV_error <- 1-sum(diag(prop.table(ct)))
print(CV_error)
}
K=3
wine_train$Y=matrix(rep(1,length(wine_test[,1])*K),ncol=K)# matrix 75 by 3
wine_train$Y[wine_train$Wine!="c",1]=-1 #if elements in wine_train$Wine is not "c",then it is -1 in the  1st column of wine_train$Y .
wine_train$Y[wine_train$Wine!="s",2]=-1
wine_train$Y[wine_train$Wine!="v",3]=-1
mod_pls <- plsr(Y ~ X, ncomp = 4, data = wine_train,
validation="LOO", scale = TRUE, jackknife = TRUE)
rfNews()
install.packages("randomForest")
library(randomForest)
obs = 2000
vars = 6
X = data.frame(replicate(vars,rnorm(obs,mean=0,sd=1)))
hidden.function = function(x,SNR=4) f
ysignal <<- with(x, .5 * X1^2 + sin(X2*pi) + X3 * X4) #y = x1^2 + sin(x2) + x3 * x4
hidden.function = function(x,SNR=4) {
ysignal <<- with(x, .5 * X1^2 + sin(X2*pi) + X3 * X4) #y = x1^2 + sin(x2) + x3 * x4
ynoise = rnorm(dim(x)[1],mean=0,sd=sd(ysignal)/SNR)
cat("actucal signal to noise ratio, SNR: nn", round(sd(ysignal)/sd(ynoise),2))
y = ysignal + ynoise
}
y = hidden.function(X)
plot(data.frame(y,X[,1:4]),col="#00004520")
print(cor(X,y))
[,1]
X1 0.072139080
X1 0.072139080
X2 0.016109836
print(cor(X,y))
X1 0.072139080
y = hidden.function(X)
y = hidden.function(X)
y = hidden.function(X)
? rmor,
?rmor
? rnorm
dnorm(1)
dnorm(10)
rnorm(1)
rnorm(10)
qnorm(10)
qnorm(0.5)
qnorm(.5 .4 .3 .2 .1)
qnorm(0.5,0.4)
qnorm(0.5,0.4,0.3,0.3)
qnorm(0.5)
qnorm(0.5,0.2)
pnorm(0.5,0.4,0.3,0.3)
dnorm(0.25,0.5)
pnorm(0.25,0.5)
print(cor(X,y))
ysignal
X
summary(X)
PLOT(X)
plot(X)
X = data.frame(replicate(vars,rnorm(obs,mean=0,sd=1)))
X = data.frame(replicate(vars,rnorm(obs,mean=0,sd=1)))
RF = randomForest(x=X,y=y,
importance=TRUE, #extra diagnostics
keep.inbag=TRUE, #track of bootstrap process
ntree=500, #how many trees
replace=FALSE) #bootstrap with replacement?
print(RF)
par(mfrow=c(1,2))
plot(RF$predicted,y,
col="#12345678",
main="prediction plot",
xlab="predicted reponse",
ylab="actual response")
abline(lm(y~yhat,data.frame(y=RF$y,yhat=RF$predicted)))
plot(y,ysignal,
col="#12345678",
main="signal and noise plot",
xlab="reponse + noise",
ylab="noise-less response")
obs = 2000
vars = 6
X = data.frame(replicate(vars,rnorm(obs,mean=0,sd=1)))
#the target/response/y depends of X by some 'unknown hidden function'
hidden.function = function(x,SNR=4) {
ysignal <<- with(x, .5 * X1^2 + sin(X2*pi) + X3 * X4) #y = x1^2 + sin(x2) + x3 * x4
ynoise = rnorm(dim(x)[1],mean=0,sd=sd(ysignal)/SNR)
cat("actucal signal to noise ratio, SNR: nn", round(sd(ysignal)/sd(ynoise),2))
y = ysignal + ynoise
}
y = hidden.function(X)
#scatter plot of X y relations
plot(data.frame(y,X[,1:4]),col="#00004520")
#no noteworthy linear relationship
print(cor(X,y))
#RF is the forest_object, randomForest is the algorithm, X & y the training data
RF = randomForest(x=X,y=y,
importance=TRUE, #extra diagnostics
keep.inbag=TRUE, #track of bootstrap process
ntree=500, #how many trees
replace=FALSE) #bootstrap with replacement?
print(RF)
par(mfrow=c(1,2))
plot(RF$predicted,y,
col="#12345678",
main="prediction plot",
xlab="predicted reponse",
ylab="actual response")
abline(lm(y~yhat,data.frame(y=RF$y,yhat=RF$predicted)))
plot(y,ysignal,
col="#12345678",
main="signal and noise plot",
xlab="reponse + noise",
ylab="noise-less response")
plot(y,ysignal,
col="#12345678",
main="signal and noise plot",
xlab="reponse + noise",
ylab="noise-less response")
cat("explained variance, (pseudo R2) = 1- SSmodel/SStotal = nn",
round(1-mean((RF$pred-y)^2)/var(y),3))
explained variance, (pseudo R2) = 1- SSmodel/SStotal =
cat("explained variance, (pseudo R2) = 1- SSmodel/SStotal = nn",
round(1-mean((RF$pred-y)^2)/var(y),3))
explained variance, (pseudo R2) = 1- SSmodel/SStotal =
cat("explained variance, (pseudo R2) = 1- SSmodel/SStotal = nn",round(1-mean((RF$pred-y)^2)/var(y),3))
cat("model correlation, (Pearson R2) = ",round(cor(RF$pred,y)^2,2))
model correlation, (Pearson R2) = 0.69
cat("signal correlation, (Pearson R2) = ",round(cor(y,ysignal)^2,2))
par(mfrow=c(1,1))
plot(RF$rsq,type="l",log="x",
ylab="prediction performance, pseudo R2",
xlab="n trees used")
RF$importance
varImpPlot(RF)
rs,rnorm(800)))
true.y = hidden.function(X2)
X2 = data.frame(replicate(vars,rnorm(800)))
true.y = hidden.function(X2)
pred.y = predict(RF,X2)
par(mfrow=c(1,1))
plot(pred.y,true.y,
main= "test-set prediction",
xlab= "predict reponse",
ylab= "true response",
col=rgb(0,0,abs(pred.y/max(pred.y)),alpha=.9))
abline(lm(true.y~pred.y,data.frame(true.y,pred.y)))
library(forestFloor, warn.conflicts=FALSE, quietly = TRUE)
library(forestFloor, warn.conflicts=FALSE, quietly = TRUE)
install.packages("forestFloor", repos="http://R-Forge.R-project.org")
library(forestFloor, warn.conflicts=FALSE, quietly = TRUE)
ff = forestFloor(RF,X)
install.packages("forestFloor", repos="http://R-Forge.R-project.org")
install.packages(c("bayesPop", "expsmooth", "formatR", "Formula", "glmnet", "gtools", "highr", "interpretR", "jsonlite", "manipulate", "Matrix", "mclust", "mgcv", "mime", "mnormt", "rstudioapi", "sandwich", "statmod"))
install.packages("randomForestSRC")
library(forestFloor, warn.conflicts=FALSE, quietly = TRUE)
install.packages("rgl")
install.packages("trimTrees")
install.packages("mlbench")
install.packages("forestFloor", repos="http://R-Forge.R-project.org")
library(forestFloor, warn.conflicts=FALSE, quietly = TRUE)
