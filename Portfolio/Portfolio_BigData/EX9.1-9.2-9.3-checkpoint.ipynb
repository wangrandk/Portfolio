{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX9.1\n",
    "Write a Spark job to count the occurrences of each word in a text file. Document that it works with a small example.\n",
    "First, I make a couple of functions to get a clean text file, then I partition the text file to RDD in a parallezied manner using \"sc.parallelize()\", which followed by a flatMap to put all words in a list with a space in between,  and then a map function to assign each word with a value \"1\", last but no least, apply a reduce function to combine the common words and \n",
    "sum their values up. I have to use collection() to take the data from RDD to local. so now I have a dictionary with all distinct words as keys and the time of their occurrences as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 725),\n",
       " ('the', 698),\n",
       " ('and', 692),\n",
       " ('you', 550),\n",
       " ('to', 482),\n",
       " ('a', 461),\n",
       " ('of', 430),\n",
       " ('that', 348),\n",
       " ('in', 319),\n",
       " ('is', 289)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "from operator import add\n",
    "\n",
    "def read_words(words_file): \n",
    "    return [word.lower() for line in open(words_file, 'r') for word in getWords(line)]\n",
    "\n",
    "def getWords(text):\n",
    "    #Extract only the words in each line\n",
    "    #If you don't care about numbers, replace \\w with [A-Za-z] for just letters.\n",
    "    return re.compile('\\w+').findall(text)\n",
    "    #return [i for i in text if i.isalpha()]\n",
    "f = read_words(\"shakespeare.txt\")\n",
    "text_file = sc.parallelize(f)\n",
    "counts = text_file.flatMap(lambda line: line.split(' ')) \\\n",
    "              .map(lambda word: (word, 1)) \\\n",
    "              .reduceByKey(add)\n",
    "output = counts.collect()\n",
    "\n",
    "from operator import itemgetter\n",
    "sorted(output, key=itemgetter(1),reverse=True)[:10]\n",
    "# order the iterm's values with ascending order, for practice purpose, I only list 10 most common words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Write a Spark job that determines if a graph has an Euler tour (all vertices have even degree) where you can assume that the graph you get is connected. \n",
    "An Euler tour has even degree for each vertices, so in order to determine a graph is an an Euler tour or not, we simply just count the degree of vertices,which implies we counts the occurrence of each vertices. If non of the vertices are odd, we can conclude that the graph is an Euler tour. First we partition the file in to RDD,then flatMap each element(vertices) with a space, and simply count the ocurrence of each elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {u'1': 2, u'0': 2, u'3': 2, u'2': 2})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"Graph01.txt\")\n",
    "counts = lines.flatMap(lambda line: line.split(' ')) \n",
    "print counts.countByValue()\n",
    "a=counts.countByValue()\n",
    "[x for x in a.values() if x % 2 != 0]\n",
    "# this gives vertices with odd degree. if it returns an empty list, it means all the vertices are even.\n",
    "# so graph01 is a Euler circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {u'1': 5, u'0': 3, u'3': 3, u'2': 3})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5, 3, 3, 3]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"graph02.txt\")\n",
    "counts = lines.flatMap(lambda line: line.split(' ')) \n",
    "print counts.countByValue()\n",
    "a=counts.countByValue()\n",
    "[x for x in a.values() if x % 2 != 0]\n",
    "# this gives vertices with odd degree. if it returns an empty list, it means all the vertices are even.\n",
    "# so graph02 is not a Euler circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {u'11': 2, u'10': 4, u'1': 4, u'0': 2, u'3': 2, u'2': 4, u'5': 4, u'4': 4, u'7': 4, u'6': 4, u'9': 4, u'8': 2})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"graph03.txt\")\n",
    "counts = lines.flatMap(lambda line: line.split(' ')) \n",
    "print counts.countByValue()\n",
    "a=counts.countByValue()\n",
    "[x for x in a.values() if x % 2 != 0]\n",
    "# this gives vertices with odd degree. if it returns an empty list, it means all the vertices are even.\n",
    "# so graph03 is a Euler circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"graph04.txt\")\n",
    "counts = lines.flatMap(lambda line: line.split(' ')) \n",
    "a=counts.countByValue()\n",
    "[x for x in a.values() if x % 2 != 0]\n",
    "# this gives vertices with odd degree. if it returns an empty list, it means all the vertices are even.\n",
    "# so graph04 is a Euler circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile(\"graph05.txt\")\n",
    "counts = lines.flatMap(lambda line: line.split(' ')) \n",
    "a=counts.countByValue()\n",
    "[x for x in a.values() if x % 2 != 0][:10]\n",
    "#[x for x in a.values() if x % 2 != 0]\n",
    "# this gives vertices with odd degree. if it returns an empty list, it means all the vertices are even.\n",
    "# For practice,I only list 10 vertices that has odd degree, so graph05 is not a Euler circuit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3.1 \n",
    "What are the 10 networks I observed the most, and how many times were they observed?\n",
    "I use sc.testFile to partion the file \"wifi.data\" to Resilient Distributed Dataset (RDD), and then do flatmap on it spliting by \",\"  to concatenate the data structure, so that each line contains only a key and a value like {u'ssid': u'NETGEAR_1'}.\n",
    "Then I use map to remove the \"{}\" that divides the file to many small dictionaries, which gives me a whole dictionary. \n",
    "Then I use \"countByValue()\" to combine the output from \"map\" with a common key, so I get a reduced result by the keys.\n",
    "Finally, I use a for loop with if statement rearching for all the keys that contain 'bssid', and sort them by the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u\" u'bssid': u'34:21:09:12:6c:1a'\", 347),\n",
       " (u\" u'bssid': u'00:24:b2:98:39:d2'\", 338),\n",
       " (u\" u'bssid': u'34:21:09:12:6c:18'\", 324),\n",
       " (u\" u'bssid': u'e8:08:8b:c9:c1:79'\", 318),\n",
       " (u\" u'bssid': u'44:94:fc:56:08:fb'\", 315),\n",
       " (u\" u'bssid': u'00:22:b0:b3:f2:ea'\", 314),\n",
       " (u\" u'bssid': u'2c:b0:5d:ef:08:2b'\", 272),\n",
       " (u\" u'bssid': u'44:94:fc:56:ce:5e'\", 240),\n",
       " (u\" u'bssid': u'28:cf:e9:84:a1:c3'\", 211),\n",
       " (u\" u'bssid': u'bc:ee:7b:55:1a:43'\", 210)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import re\n",
    "\n",
    "lines = sc.textFile(\"wifi.data\")\n",
    "#counts = lines.flatMap(lambda line: line.strip(\"{}\").split(','))\\\n",
    "#.map(lambda x: (re.search(r'bssid',x.keys()))).countByValue()\n",
    "counts = lines.flatMap(lambda line: line.split(','))\\\n",
    ".map(lambda x: (x.strip(\"{}\"))).countByValue()\n",
    "#type(counts)\n",
    "#counts\n",
    "sorted([(k,v) for k,v in counts.items() if re.search(r'bssid',k)],key=itemgetter(1),reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3.2\n",
    "What are the 10 most common wifi names? (ssid)\n",
    "The maping and reducing parts are done in the same manner as in 9.3.1, the only difference is the last step, where instead of searching for \"bssid\",I search for \"ssid\", which refers to the Wifi name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u\"u'ssid': u'Kaspers Wi-Fi-netv\\\\xe6rk'\", 402),\n",
       " (u\"u'ssid': u'Internet4realz'\", 402),\n",
       " (u\" u'bssid': u'34:21:09:12:6c:1a'\", 347),\n",
       " (u\"u'ssid': u'AirLink5GHz126C18'\", 347),\n",
       " (u\" u'bssid': u'00:24:b2:98:39:d2'\", 338),\n",
       " (u\"u'ssid': u'NETGEAR_1'\", 338),\n",
       " (u\"u'ssid': u'AirLink126C18'\", 324),\n",
       " (u\" u'bssid': u'34:21:09:12:6c:18'\", 324),\n",
       " (u\"u'ssid': u'Housing People'\", 318),\n",
       " (u\" u'bssid': u'e8:08:8b:c9:c1:79'\", 318)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "import re\n",
    "lines = sc.textFile(\"wifi.data\")\n",
    "counts = lines.flatMap(lambda line: line.split(','))\\\n",
    ".map(lambda x: (x.strip(\"{}\"))).countByValue()\n",
    "\n",
    "sorted([(k,v) for k,v in counts.items() if re.search(r'ssid',k)],key=itemgetter(1),reverse=True)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.3.3. What are the 10 longest wifi names? (again, ssid)\n",
    "The mapping and reducing parts are done in the same way like the two previous exercises, the only difference is the way sorting the dictionary. I make three out put of the for loop, the new one is the length of key in third column, and sort it by the third column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u\"u'ssid': u'HP-Print-43-Deskjet 3520 series'\", 2, 43),\n",
       " (u\"u'ssid': u'Charlotte R.s Wi-Fi-netv\\\\xe6rk'\", 4, 42),\n",
       " (u\"u'ssid': u'TeliaGateway08-76-FF-8A-EE-32'\", 20, 41),\n",
       " (u\"u'ssid': u'Emil M\\\\xf8rkebergs Netv\\\\xe6rk'\", 2, 41),\n",
       " (u\"u'ssid': u'TeliaGateway08-76-FF-46-3E-36'\", 2, 41),\n",
       " (u\"u'ssid': u'TeliaGateway9C-97-26-57-15-99'\", 5, 41),\n",
       " (u\"u'ssid': u'TeliaGateway08-76-FF-85-04-2F'\", 2, 41),\n",
       " (u\"u'ssid': u'TeliaGatewayA4-B1-E9-2C-9E-CA'\", 2, 41),\n",
       " (u\"u'ssid': u'TeliaGateway9C-97-26-57-15-F9'\", 2, 41),\n",
       " (u\"u'ssid': u'TeliaGateway08-76-FF-84-FF-8C'\", 2, 41)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k,v,len(k) ) for k,v in counts.items() if re.search(r'ssid',k)],key=itemgetter(2),reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " For instance the longest WiFi name is \"u'ssid': u'HP-Print-43-Deskjet 3520 series'\" has 43 bits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
